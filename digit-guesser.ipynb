{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc6e74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "data=tf.keras.datasets.mnist.load_data(\n",
    "    path='mnist.npz'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9e98126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e4d9f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "X_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train.shape: {}\".format(X_train.shape)) \n",
    "print (\"y_train.shape: {}\".format(y_train.shape)) \n",
    "print (\"X_test.shape: {}\".format(X_test.shape)) \n",
    "print (\"y_test.shape: {}\".format(y_test.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a049d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# One-Hot Encode outputs \n",
    "y_train = keras.utils.to_categorical(y_train) \n",
    "y_test = keras.utils.to_categorical(y_test) \n",
    "num_classes = 10\n",
    "  \n",
    "# Training model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "93ed2757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000, 10)\n",
      "X_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train.shape: {}\".format(X_train.shape)) \n",
    "print (\"y_train.shape: {}\".format(y_train.shape)) \n",
    "print (\"X_test.shape: {}\".format(X_test.shape)) \n",
    "print (\"y_test.shape: {}\".format(y_test.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "26bf196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f856cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.expand_dims(X_train,axis=3)\n",
    "X_test=np.expand_dims(X_test,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9e413e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6630f88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10, 10),\n",
       " (60000, 10),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a97253a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "860890af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),input_shape=(28,28,1),activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c49dfc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model=tf.keras.models.Sequential([\\n    tf.keras.layers.Conv2D(16,(3,3),input_shape=(28,28,1),activation=tf.nn.relu),\\n    tf.keras.layers.MaxPooling2D((2,2)),\\n    tf.keras.layers.Conv2D(32,(3,3),activation=tf.nn.relu)\\n    tf.keras.layers.MaxPool2D((2,2))\\n    tf.keras.layers.Flatten(),\\n    tf.keras.layers.Dense(128,activation=tf.nn.relu),\\n    tf.keras.layers.Dense(64,activation=tf.nn.relu),\\n    tf.keras.layers.Dense(32,activation=tf.nn.relu)\\n    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\\n])'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),input_shape=(28,28,1),activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation=tf.nn.relu)\n",
    "    tf.keras.layers.MaxPool2D((2,2))\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(32,activation=tf.nn.relu)\n",
    "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "055b2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2704)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               346240    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355,306\n",
      "Trainable params: 355,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8d100a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "'''model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[tf.keras.metrics.Accuracy(\n",
    "              )])\n",
    "'''\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.Accuracy()]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75188995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0043 - accuracy: 0.2777 - val_loss: 0.1578 - val_accuracy: 0.3214\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0037 - accuracy: 0.2995 - val_loss: 0.1808 - val_accuracy: 0.3154\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0060 - accuracy: 0.3006 - val_loss: 0.1582 - val_accuracy: 0.3094\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0034 - accuracy: 0.3101 - val_loss: 0.1588 - val_accuracy: 0.3046\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0046 - accuracy: 0.3191 - val_loss: 0.1878 - val_accuracy: 0.3501\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0044 - accuracy: 0.3261 - val_loss: 0.2012 - val_accuracy: 0.3717\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0027 - accuracy: 0.3749 - val_loss: 0.1820 - val_accuracy: 0.4074\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.3813 - val_loss: 0.1709 - val_accuracy: 0.3480\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0046 - accuracy: 0.3529 - val_loss: 0.1629 - val_accuracy: 0.3794\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0037 - accuracy: 0.3920 - val_loss: 0.1671 - val_accuracy: 0.4005\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0051 - accuracy: 0.4256 - val_loss: 0.2001 - val_accuracy: 0.4592\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0029 - accuracy: 0.4370 - val_loss: 0.2008 - val_accuracy: 0.4572\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.4387 - val_loss: 0.1955 - val_accuracy: 0.4559\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0041 - accuracy: 0.4470 - val_loss: 0.2025 - val_accuracy: 0.4530\n",
      "Epoch 15/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0027 - accuracy: 0.4626 - val_loss: 0.2264 - val_accuracy: 0.5101\n",
      "Epoch 16/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0048 - accuracy: 0.4980 - val_loss: 0.1846 - val_accuracy: 0.4922\n",
      "Epoch 17/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0035 - accuracy: 0.4800 - val_loss: 0.1966 - val_accuracy: 0.5018\n",
      "Epoch 18/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0047 - accuracy: 0.4882 - val_loss: 0.2001 - val_accuracy: 0.5455\n",
      "Epoch 19/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 8.3598e-04 - accuracy: 0.5339 - val_loss: 0.1959 - val_accuracy: 0.5472\n",
      "Epoch 20/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0056 - accuracy: 0.5220 - val_loss: 0.2074 - val_accuracy: 0.5451\n",
      "Epoch 21/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0057 - accuracy: 0.5424 - val_loss: 0.2278 - val_accuracy: 0.5266\n",
      "Epoch 22/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0028 - accuracy: 0.5318 - val_loss: 0.2131 - val_accuracy: 0.5701\n",
      "Epoch 23/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0052 - accuracy: 0.5499 - val_loss: 0.1980 - val_accuracy: 0.5480\n",
      "Epoch 24/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0028 - accuracy: 0.5323 - val_loss: 0.1803 - val_accuracy: 0.5290\n",
      "Epoch 25/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0040 - accuracy: 0.5711 - val_loss: 0.2080 - val_accuracy: 0.5909\n",
      "Epoch 26/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0037 - accuracy: 0.5839 - val_loss: 0.2088 - val_accuracy: 0.6106\n",
      "Epoch 27/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 9.3576e-04 - accuracy: 0.5949 - val_loss: 0.2025 - val_accuracy: 0.6106\n",
      "Epoch 28/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0054 - accuracy: 0.5757 - val_loss: 0.2333 - val_accuracy: 0.5962\n",
      "Epoch 29/100\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.0048 - accuracy: 0.5947 - val_loss: 0.1860 - val_accuracy: 0.5908\n",
      "Epoch 30/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0045 - accuracy: 0.5921 - val_loss: 0.1895 - val_accuracy: 0.5788\n",
      "Epoch 31/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0031 - accuracy: 0.5954 - val_loss: 0.2270 - val_accuracy: 0.6134\n",
      "Epoch 32/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0054 - accuracy: 0.6006 - val_loss: 0.2316 - val_accuracy: 0.6101\n",
      "Epoch 33/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0016 - accuracy: 0.6118 - val_loss: 0.2155 - val_accuracy: 0.6245\n",
      "Epoch 34/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0056 - accuracy: 0.6070 - val_loss: 0.2113 - val_accuracy: 0.6157\n",
      "Epoch 35/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0023 - accuracy: 0.6339 - val_loss: 0.2394 - val_accuracy: 0.6519\n",
      "Epoch 36/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0024 - accuracy: 0.6563 - val_loss: 0.2529 - val_accuracy: 0.6632\n",
      "Epoch 37/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0053 - accuracy: 0.6788 - val_loss: 0.2757 - val_accuracy: 0.6697\n",
      "Epoch 38/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0068 - accuracy: 0.6780 - val_loss: 0.2691 - val_accuracy: 0.6860\n",
      "Epoch 39/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0035 - accuracy: 0.6857 - val_loss: 0.2983 - val_accuracy: 0.7089\n",
      "Epoch 40/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0043 - accuracy: 0.6982 - val_loss: 0.3296 - val_accuracy: 0.7073\n",
      "Epoch 41/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0050 - accuracy: 0.7178 - val_loss: 0.2915 - val_accuracy: 0.7171\n",
      "Epoch 42/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0045 - accuracy: 0.7101 - val_loss: 0.2786 - val_accuracy: 0.7303\n",
      "Epoch 43/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0061 - accuracy: 0.7261 - val_loss: 0.2392 - val_accuracy: 0.6973\n",
      "Epoch 44/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0020 - accuracy: 0.7125 - val_loss: 0.2891 - val_accuracy: 0.7196\n",
      "Epoch 45/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0043 - accuracy: 0.7074 - val_loss: 0.2687 - val_accuracy: 0.7115\n",
      "Epoch 46/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0029 - accuracy: 0.7147 - val_loss: 0.2801 - val_accuracy: 0.7325\n",
      "Epoch 47/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0052 - accuracy: 0.7610 - val_loss: 0.3580 - val_accuracy: 0.7712\n",
      "Epoch 48/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0043 - accuracy: 0.7685 - val_loss: 0.2913 - val_accuracy: 0.7674\n",
      "Epoch 49/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0017 - accuracy: 0.7755 - val_loss: 0.3075 - val_accuracy: 0.7905\n",
      "Epoch 50/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0045 - accuracy: 0.7715 - val_loss: 0.2624 - val_accuracy: 0.7697\n",
      "Epoch 51/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0052 - accuracy: 0.7735 - val_loss: 0.2762 - val_accuracy: 0.7656\n",
      "Epoch 52/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0012 - accuracy: 0.7821 - val_loss: 0.3019 - val_accuracy: 0.8001\n",
      "Epoch 53/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0041 - accuracy: 0.8033 - val_loss: 0.3527 - val_accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0038 - accuracy: 0.8203 - val_loss: 0.3607 - val_accuracy: 0.8365\n",
      "Epoch 55/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0037 - accuracy: 0.8332 - val_loss: 0.3103 - val_accuracy: 0.8212\n",
      "Epoch 56/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0063 - accuracy: 0.8249 - val_loss: 0.2802 - val_accuracy: 0.8215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0050 - accuracy: 0.8205 - val_loss: 0.3753 - val_accuracy: 0.8245\n",
      "Epoch 58/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0052 - accuracy: 0.8399 - val_loss: 0.3606 - val_accuracy: 0.8482\n",
      "Epoch 59/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0043 - accuracy: 0.8512 - val_loss: 0.3489 - val_accuracy: 0.8645\n",
      "Epoch 60/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0018 - accuracy: 0.8613 - val_loss: 0.3349 - val_accuracy: 0.8634\n",
      "Epoch 61/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0062 - accuracy: 0.8554 - val_loss: 0.3007 - val_accuracy: 0.8681\n",
      "Epoch 62/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0066 - accuracy: 0.8644 - val_loss: 0.3882 - val_accuracy: 0.8332\n",
      "Epoch 63/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0040 - accuracy: 0.8562 - val_loss: 0.3075 - val_accuracy: 0.8475\n",
      "Epoch 64/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0036 - accuracy: 0.8590 - val_loss: 0.3186 - val_accuracy: 0.8466\n",
      "Epoch 65/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0043 - accuracy: 0.8738 - val_loss: 0.3190 - val_accuracy: 0.8544\n",
      "Epoch 66/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0033 - accuracy: 0.8690 - val_loss: 0.3382 - val_accuracy: 0.8582\n",
      "Epoch 67/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0057 - accuracy: 0.8593 - val_loss: 0.3003 - val_accuracy: 0.8614\n",
      "Epoch 68/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0056 - accuracy: 0.8610 - val_loss: 0.2970 - val_accuracy: 0.8891\n",
      "Epoch 69/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0011 - accuracy: 0.8724 - val_loss: 0.3384 - val_accuracy: 0.8653\n",
      "Epoch 70/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0060 - accuracy: 0.8841 - val_loss: 0.3754 - val_accuracy: 0.8871\n",
      "Epoch 71/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0034 - accuracy: 0.8880 - val_loss: 0.3065 - val_accuracy: 0.8857\n",
      "Epoch 72/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.8870 - val_loss: 0.3462 - val_accuracy: 0.8921\n",
      "Epoch 73/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.8919 - val_loss: 0.3403 - val_accuracy: 0.8802\n",
      "Epoch 74/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0051 - accuracy: 0.8852 - val_loss: 0.3834 - val_accuracy: 0.8903\n",
      "Epoch 75/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0021 - accuracy: 0.8934 - val_loss: 0.3971 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0066 - accuracy: 0.8950 - val_loss: 0.3340 - val_accuracy: 0.8831\n",
      "Epoch 77/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0034 - accuracy: 0.8966 - val_loss: 0.3798 - val_accuracy: 0.8946\n",
      "Epoch 78/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0019 - accuracy: 0.8996 - val_loss: 0.3386 - val_accuracy: 0.8946\n",
      "Epoch 79/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0065 - accuracy: 0.8975 - val_loss: 0.3547 - val_accuracy: 0.8672\n",
      "Epoch 80/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.8832 - val_loss: 0.4131 - val_accuracy: 0.8857\n",
      "Epoch 81/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0055 - accuracy: 0.8938 - val_loss: 0.3824 - val_accuracy: 0.9053\n",
      "Epoch 82/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 9.5461e-04 - accuracy: 0.8982 - val_loss: 0.3907 - val_accuracy: 0.9016\n",
      "Epoch 83/100\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0044 - accuracy: 0.8932 - val_loss: 0.3429 - val_accuracy: 0.8926\n",
      "Epoch 84/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0040 - accuracy: 0.8967 - val_loss: 0.3896 - val_accuracy: 0.9011\n",
      "Epoch 85/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0036 - accuracy: 0.9077 - val_loss: 0.3895 - val_accuracy: 0.9089\n",
      "Epoch 86/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0034 - accuracy: 0.9198 - val_loss: 0.4568 - val_accuracy: 0.8943\n",
      "Epoch 87/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0093 - accuracy: 0.9068 - val_loss: 0.3673 - val_accuracy: 0.9022\n",
      "Epoch 88/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0027 - accuracy: 0.9049 - val_loss: 0.3625 - val_accuracy: 0.8976\n",
      "Epoch 89/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0046 - accuracy: 0.9063 - val_loss: 0.3467 - val_accuracy: 0.8937\n",
      "Epoch 90/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0040 - accuracy: 0.9075 - val_loss: 0.4363 - val_accuracy: 0.9032\n",
      "Epoch 91/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0050 - accuracy: 0.9003 - val_loss: 0.3894 - val_accuracy: 0.8941\n",
      "Epoch 92/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0043 - accuracy: 0.9121 - val_loss: 0.4025 - val_accuracy: 0.9148\n",
      "Epoch 93/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0032 - accuracy: 0.9180 - val_loss: 0.4110 - val_accuracy: 0.9165\n",
      "Epoch 94/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0030 - accuracy: 0.9276 - val_loss: 0.4241 - val_accuracy: 0.9202\n",
      "Epoch 95/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0035 - accuracy: 0.9267 - val_loss: 0.3836 - val_accuracy: 0.9149\n",
      "Epoch 96/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0027 - accuracy: 0.9309 - val_loss: 0.4323 - val_accuracy: 0.9299\n",
      "Epoch 97/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0053 - accuracy: 0.9379 - val_loss: 0.3940 - val_accuracy: 0.9303\n",
      "Epoch 98/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0060 - accuracy: 0.9372 - val_loss: 0.4326 - val_accuracy: 0.9180\n",
      "Epoch 99/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0031 - accuracy: 0.9366 - val_loss: 0.4092 - val_accuracy: 0.9368\n",
      "Epoch 100/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0062 - accuracy: 0.9354 - val_loss: 0.4374 - val_accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed3a3228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000, 10, 10))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886c444",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "07feea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"digit_predictor_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "44febfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dig7=image.array_to_img(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4213c429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c66202a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape\n",
    "assign=np.argmax(pred)\n",
    "assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1e8a7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a8286d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: digit_guesser_visualize.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: digit_guesser_visualize.pb\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"digit_guesser_visualize.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c8503b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fe87ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_predictions(pred):\n",
    "    \n",
    "    m,n=pred.shape\n",
    "    assign=[]\n",
    "    for i in range(m):\n",
    "        assign.append(np.argmax(pred[i]))\n",
    "    \n",
    "    return assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0d37a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=assign_predictions(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7dd3a76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f91825a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " ...]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=assign_predictions(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "04c353f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99815"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28cf0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
